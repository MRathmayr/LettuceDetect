component,dataset,n_samples,auroc,f1,optimal_f1,latency_mean_ms,latency_p95_ms,gpu_peak_mb
lexical,ragtruth,20,0.5466666666666667,0.4,0.49999999531250006,7.65,10.44,None
lexical,halueval_qa,20,0.20202020202020202,0.6206896551724138,0.642857138494898,0.74,1.11,None
lexical,halueval_dialogue,20,0.2828282828282828,0.6206896551724138,0.6206896508917956,0.39,0.56,None
lexical,halueval_summarization,20,0.2222222222222222,0.6206896551724138,0.6206896508917956,6.46,11.35,None
numeric,ragtruth,20,0.5,0.0,0.39999999680000003,0.50,0.68,None
numeric,halueval_qa,20,0.5555555555555556,0.2,0.6206896508917956,0.07,0.11,None
numeric,halueval_dialogue,20,0.45454545454545453,0.0,0.6206896508917956,0.03,0.04,None
numeric,halueval_summarization,20,0.5555555555555556,0.2,0.6206896508917956,0.45,0.77,None
ner,ragtruth,20,0.6,0.0,0.4615384568047337,94.40,144.76,None
ner,halueval_qa,20,0.7020202020202019,0.5333333333333333,0.7058823479584776,12.84,18.07,None
ner,halueval_dialogue,20,0.5909090909090908,0.631578947368421,0.6315789423822715,7.73,9.90,None
ner,halueval_summarization,20,0.5606060606060607,0.18181818181818182,0.6206896508917956,87.56,140.53,None
transformer,ragtruth,20,0.6,0.3333333333333333,0.39999999680000003,157.15,214.02,670.5517578125
transformer,halueval_qa,20,0.6363636363636362,0.46153846153846156,0.6206896508917956,21.95,24.08,607.40576171875
transformer,halueval_dialogue,20,0.6919191919191919,0.6956521739130435,0.7272727224380167,22.12,24.96,606.70361328125
transformer,halueval_summarization,20,0.48484848484848486,0.4,0.6206896508917956,77.73,132.40,670.3828125
model2vec,ragtruth,20,0.56,0.0,0.4545454510330579,1.05,1.29,None
model2vec,halueval_qa,20,0.19191919191919193,0.0,0.6206896508917956,0.26,0.35,None
model2vec,halueval_dialogue,20,0.2828282828282828,0.0,0.642857138494898,0.19,0.22,None
model2vec,halueval_summarization,20,0.36363636363636365,0.0,0.642857138494898,0.99,1.25,None
nli,ragtruth,20,0.8266666666666667,0.0,0.7499999953125,79.91,233.65,815.49658203125
nli,halueval_qa,20,0.6565656565656566,0.6153846153846154,0.6666666618666668,30.91,33.86,738.4365234375
nli,halueval_dialogue,20,0.8080808080808081,0.46153846153846156,0.782608690888469,14.25,15.81,725.98681640625
nli,halueval_summarization,20,0.6565656565656566,0.36363636363636365,0.6666666622222223,58.27,65.12,815.49658203125
stage1,ragtruth,20,0.74,0.5333333333333333,0.533333328888889,217.87,319.02,668.7841796875
stage1,halueval_qa,20,0.7575757575757576,0.6666666666666666,0.7058823479584776,40.24,50.00,607.29150390625
stage1,halueval_dialogue,20,0.6919191919191919,0.6956521739130435,0.7272727224380167,34.72,41.78,606.681640625
stage1,halueval_summarization,20,0.5656565656565656,0.6666666666666666,0.6666666617687076,187.21,299.78,668.533203125
stage2,ragtruth,20,0.5,0.0,0.39999999680000003,63.86,66.36,817.24658203125
stage2,halueval_qa,20,0.7777777777777778,0.7142857142857143,0.7142857096938776,16.68,19.81,739.3115234375
stage2,halueval_dialogue,20,0.4444444444444444,0.4444444444444444,0.6206896508917956,14.82,16.65,726.86181640625
stage2,halueval_summarization,20,0.5,0.0,0.6206896508917956,60.24,66.38,817.24658203125
cascade_stages12,ragtruth,20,0.4,0.0,0.4347826052930058,283.04,392.08,2112.63330078125
cascade_stages12,halueval_qa,20,0.7171717171717171,0.7142857142857143,0.7499999950781251,56.80,70.57,2033.5732421875
cascade_stages12,halueval_dialogue,20,0.3535353535353536,0.42105263157894735,0.642857138494898,48.51,56.96,2021.12353515625
cascade_stages12,halueval_summarization,20,0.36363636363636365,0.0,0.642857138494898,246.50,361.56,2112.63330078125
